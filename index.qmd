---
title: "Garbage Can Regression Challenge"
format:
  html: default
execute:
  echo: false
  eval: true
---

# Questions to answer for 75% grade on challenge

## Question 1: Run a bivariate regression of anxiety on stresssurvey. What are the estimated coefficients? How do they compare to the true relationship?

**Choose R or Python and delete the other code chunk.**


## Python Code

```{python}
#| echo: false
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score
import statsmodels.api as sm

# Data with known true relationships: Anxiety = Stress + 0.1 × Time
data = {
    'Stress': [0,0,0,1,1,1,2,2,2,8,8,8,12,12,12],
    'StressSurvey': [0,0,0,3,3,3,6,6,6,9,9,9,12,12,12],
    'Time': [0,1,1,1,1,1,2,2,2,2,2,2.1,2.2,2.2,2.2],
    'Anxiety': [0,0.1,0.1,1.1,1.1,1.1,2.2,2.2,2.2,8.2,8.2,8.21,12.22,12.22,12.22]
}

observDF = pd.DataFrame(data)
print(observDF)
```

## Your Analysis

Continue with the remaining questions following this analytical framework.


## Question 1 Analysis: Bivariate Regression of Anxiety on StressSurvey

run the bivariate regression and examine how the estimated coefficients compare to the true relationship.

### Python Analysis

```{python}
#| echo: false
# Run bivariate regression of Anxiety on StressSurvey
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_squared_error

# Prepare data for regression
X = observDF[['StressSurvey']].values
y = observDF['Anxiety'].values

# Fit the linear regression model
model = LinearRegression()
model.fit(X, y)

# Get predictions
y_pred = model.predict(X)

# Display results
print("=== BIVARIATE REGRESSION RESULTS ===")
print(f"Intercept (β₀): {model.intercept_:.6f}")
print(f"Slope (β₁): {model.coef_[0]:.6f}")
print(f"R-squared: {r2_score(y, y_pred):.6f}")
print(f"RMSE: {np.sqrt(mean_squared_error(y, y_pred)):.6f}")

# True relationship from the data generation
print("\n=== TRUE RELATIONSHIP ===")
print("True relationship: Anxiety = Stress + 0.1 × Time")
print("But we're regressing Anxiety on StressSurvey, not Stress!")

# Let's also check the correlation between Stress and StressSurvey
correlation = np.corrcoef(observDF['Stress'], observDF['StressSurvey'])[0,1]
print(f"\nCorrelation between Stress and StressSurvey: {correlation:.6f}")

# Create two specific visualizations for Question 1
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))

# Graph 1: Estimated Coefficients
ax1.scatter(observDF['StressSurvey'], observDF['Anxiety'], alpha=0.7, color='blue', s=60, label='Observed Data')
ax1.plot(observDF['StressSurvey'], y_pred, color='red', linewidth=3, label=f'Estimated Line: y = {model.intercept_:.3f} + {model.coef_[0]:.3f}x')
ax1.set_xlabel('StressSurvey', fontsize=12)
ax1.set_ylabel('Anxiety', fontsize=12)
ax1.set_title('Estimated Coefficients: Bivariate Regression\nAnxiety ~ StressSurvey', fontsize=14, fontweight='bold')
ax1.legend(fontsize=10)
ax1.grid(True, alpha=0.3)
ax1.text(0.05, 0.95, f'Slope (β₁): {model.coef_[0]:.4f}\nIntercept (β₀): {model.intercept_:.4f}\nR²: {r2_score(y, y_pred):.4f}', 
         transform=ax1.transAxes, fontsize=10, verticalalignment='top',
         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))

# Graph 2: Compare to True Relationships
# Calculate true relationship values
true_anxiety = observDF['Stress'] + 0.1 * observDF['Time']
ax2.scatter(observDF['StressSurvey'], observDF['Anxiety'], alpha=0.7, color='blue', s=60, label='Observed Anxiety')
ax2.scatter(observDF['StressSurvey'], true_anxiety, alpha=0.7, color='green', s=60, marker='s', label='True Relationship: Stress + 0.1×Time')
ax2.plot(observDF['StressSurvey'], y_pred, color='red', linewidth=3, label=f'Estimated Line: y = {model.intercept_:.3f} + {model.coef_[0]:.3f}x')
ax2.set_xlabel('StressSurvey', fontsize=12)
ax2.set_ylabel('Anxiety', fontsize=12)
ax2.set_title('Comparison: Estimated vs True Relationships', fontsize=14, fontweight='bold')
ax2.legend(fontsize=10)
ax2.grid(True, alpha=0.3)

# Add comparison text
mse_estimated = mean_squared_error(observDF['Anxiety'], y_pred)
mse_true = mean_squared_error(observDF['Anxiety'], true_anxiety)
ax2.text(0.05, 0.95, f'True relationship: Anxiety = Stress + 0.1×Time\nMSE (Estimated): {mse_estimated:.4f}\nMSE (True): {mse_true:.4f}', 
         transform=ax2.transAxes, fontsize=10, verticalalignment='top',
         bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.8))

plt.tight_layout()
plt.show()

# Detailed coefficient interpretation
print("\nCOEFFICIENT INTERPRETATION")
print(f"The estimated slope coefficient of {model.coef_[0]:.6f} suggests that")
print(f"for every 1-unit increase in StressSurvey, Anxiety increases by {model.coef_[0]:.6f} units.")

```

### What This Tells Us About Linear Regression

Looking at these results, we can see some pretty significant issues with how we're interpreting our regression model, This is exactly why we need to be careful with regression results. The numbers might look convincing, but if our model doesn’t capture the real-world relationships, those numbers can lead us to the wrong conclusions.




