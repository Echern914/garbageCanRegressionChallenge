---
title: "Garbage Can Regression Challenge"
format:
  html: default
execute:
  echo: false
  eval: true
---

# Questions to answer for 75% grade on challenge

## Question 1: Run a bivariate regression of anxiety on stresssurvey. What are the estimated coefficients? How do they compare to the true relationship?

**Choose R or Python and delete the other code chunk.**


## Python Code

```{python}
#| echo: false
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score
import statsmodels.api as sm

# Data with known true relationships: Anxiety = Stress + 0.1 × Time
data = {
    'Stress': [0,0,0,1,1,1,2,2,2,8,8,8,12,12,12],
    'StressSurvey': [0,0,0,3,3,3,6,6,6,9,9,9,12,12,12],
    'Time': [0,1,1,1,1,1,2,2,2,2,2,2.1,2.2,2.2,2.2],
    'Anxiety': [0,0.1,0.1,1.1,1.1,1.1,2.2,2.2,2.2,8.2,8.2,8.21,12.22,12.22,12.22]
}

observDF = pd.DataFrame(data)
print(observDF)
```

## Your Analysis

Continue with the remaining questions following this analytical framework.


## Question 1 Analysis: Bivariate Regression of Anxiety on StressSurvey

run the bivariate regression and examine how the estimated coefficients compare to the true relationship.

### Python Analysis

```{python}
#| echo: false
# Run bivariate regression of Anxiety on StressSurvey
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_squared_error

# Prepare data for regression
X = observDF[['StressSurvey']].values
y = observDF['Anxiety'].values

# Fit the linear regression model
model = LinearRegression()
model.fit(X, y)

# Get predictions
y_pred = model.predict(X)

# Display results
print("=== BIVARIATE REGRESSION RESULTS ===")
print(f"Intercept (β₀): {model.intercept_:.6f}")
print(f"Slope (β₁): {model.coef_[0]:.6f}")
print(f"R-squared: {r2_score(y, y_pred):.6f}")
print(f"RMSE: {np.sqrt(mean_squared_error(y, y_pred)):.6f}")

# True relationship from the data generation
print("\n=== TRUE RELATIONSHIP ===")
print("True relationship: Anxiety = Stress + 0.1 × Time")
print("But we're regressing Anxiety on StressSurvey, not Stress!")

# Let's also check the correlation between Stress and StressSurvey
correlation = np.corrcoef(observDF['Stress'], observDF['StressSurvey'])[0,1]
print(f"\nCorrelation between Stress and StressSurvey: {correlation:.6f}")

# Create two specific visualizations for Question 1
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))

# Graph 1: Estimated Coefficients
ax1.scatter(observDF['StressSurvey'], observDF['Anxiety'], alpha=0.7, color='blue', s=60, label='Observed Data')
ax1.plot(observDF['StressSurvey'], y_pred, color='red', linewidth=3, label=f'Estimated Line: y = {model.intercept_:.3f} + {model.coef_[0]:.3f}x')
ax1.set_xlabel('StressSurvey', fontsize=12)
ax1.set_ylabel('Anxiety', fontsize=12)
ax1.set_title('Estimated Coefficients: Bivariate Regression\nAnxiety ~ StressSurvey', fontsize=14, fontweight='bold')
ax1.legend(fontsize=10)
ax1.grid(True, alpha=0.3)
ax1.text(0.05, 0.95, f'Slope (β₁): {model.coef_[0]:.4f}\nIntercept (β₀): {model.intercept_:.4f}\nR²: {r2_score(y, y_pred):.4f}', 
         transform=ax1.transAxes, fontsize=10, verticalalignment='top',
         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))

# Graph 2: Compare to True Relationships
# Calculate true relationship values
true_anxiety = observDF['Stress'] + 0.1 * observDF['Time']
ax2.scatter(observDF['StressSurvey'], observDF['Anxiety'], alpha=0.7, color='blue', s=60, label='Observed Anxiety')
ax2.scatter(observDF['StressSurvey'], true_anxiety, alpha=0.7, color='green', s=60, marker='s', label='True Relationship: Stress + 0.1×Time')
ax2.plot(observDF['StressSurvey'], y_pred, color='red', linewidth=3, label=f'Estimated Line: y = {model.intercept_:.3f} + {model.coef_[0]:.3f}x')
ax2.set_xlabel('StressSurvey', fontsize=12)
ax2.set_ylabel('Anxiety', fontsize=12)
ax2.set_title('Comparison: Estimated vs True Relationships', fontsize=14, fontweight='bold')
ax2.legend(fontsize=10)
ax2.grid(True, alpha=0.3)

# Add comparison text
mse_estimated = mean_squared_error(observDF['Anxiety'], y_pred)
mse_true = mean_squared_error(observDF['Anxiety'], true_anxiety)
ax2.text(0.05, 0.95, f'True relationship: Anxiety = Stress + 0.1×Time\nMSE (Estimated): {mse_estimated:.4f}\nMSE (True): {mse_true:.4f}', 
         transform=ax2.transAxes, fontsize=10, verticalalignment='top',
         bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.8))

plt.tight_layout()
plt.show()

# Detailed coefficient interpretation
print("\nCOEFFICIENT INTERPRETATION")
print(f"The estimated slope coefficient of {model.coef_[0]:.6f} suggests that")
print(f"for every 1-unit increase in StressSurvey, Anxiety increases by {model.coef_[0]:.6f} units.")

```

### What This Tells Us About Linear Regression

Looking at these results, we can see some pretty significant issues with how we're interpreting our regression model, This is exactly why we need to be careful with regression results. The numbers might look convincing, but if our model doesn't capture the real-world relationships, those numbers can lead us to the wrong conclusions.


## Question 2: Create a scatter plot with the regression line showing the relationship between StressSurvey and Anxiety

Let's create a focused scatter plot to examine the relationship between StressSurvey and Anxiety, and comment on the fit and potential issues.

```{python}
#| echo: false
# Create a detailed scatter plot with regression line and coordinate points
plt.figure(figsize=(12, 8))

# Scatter plot with regression line
plt.scatter(observDF['StressSurvey'], observDF['Anxiety'], alpha=0.7, color='steelblue', s=80, edgecolors='white', linewidth=1)
plt.plot(observDF['StressSurvey'], y_pred, color='red', linewidth=3, label=f'Regression Line: y = {model.intercept_:.3f} + {model.coef_[0]:.3f}x')

# Add coordinate points for each data point
for i, row in observDF.iterrows():
    plt.annotate(f'({row["StressSurvey"]}, {row["Anxiety"]})', 
                (row['StressSurvey'], row['Anxiety']),
                xytext=(5, 5), textcoords='offset points',
                fontsize=9, alpha=0.8, color='darkblue',
                bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.7, edgecolor='none'))

# Add some styling
plt.xlabel('StressSurvey Score', fontsize=12, fontweight='bold')
plt.ylabel('Anxiety Level', fontsize=12, fontweight='bold')
plt.title('Relationship Between StressSurvey and Anxiety\nWith Linear Regression Line and Coordinate Points', fontsize=14, fontweight='bold')
plt.legend(fontsize=11)
plt.grid(True, alpha=0.3)

# Add R-squared and correlation info
r_squared = r2_score(y, y_pred)
correlation = np.corrcoef(observDF['StressSurvey'], observDF['Anxiety'])[0,1]
plt.text(0.05, 0.95, f'R² = {r_squared:.4f}\nCorrelation = {correlation:.4f}', 
         transform=plt.gca().transAxes, fontsize=11, verticalalignment='top',
         bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))

plt.tight_layout()
plt.show()

# Comment on the fit
print("=== ANALYSIS OF THE FIT ===")
print(f"The regression line shows a strong positive relationship (R² = {r_squared:.4f})")
print(f"between StressSurvey and Anxiety, with a correlation of {correlation:.4f}.")
```

## Question 3: Run a bivariate regression showing the relationship between Time and Anxiety

Now let's examine the relationship between Time and Anxiety, which is part of the true relationship but often overlooked.

```{python}
#| echo: false
# Run bivariate regression of Anxiety on Time
X_time = observDF[['Time']].values
y_time = observDF['Anxiety'].values

# Fit the linear regression model for Time
model_time = LinearRegression()
model_time.fit(X_time, y_time)

# Get predictions
y_pred_time = model_time.predict(X_time)

# Display results
print("=== TIME-ANXIETY REGRESSION RESULTS ===")
print(f"Intercept (β₀): {model_time.intercept_:.6f}")
print(f"Slope (β₁): {model_time.coef_[0]:.6f}")
print(f"R-squared: {r2_score(y_time, y_pred_time):.6f}")
print(f"RMSE: {np.sqrt(mean_squared_error(y_time, y_pred_time)):.6f}")

# Create scatter plot with regression line
plt.figure(figsize=(12, 8))

# Scatter plot with regression line
plt.scatter(observDF['Time'], observDF['Anxiety'], alpha=0.7, color='darkgreen', s=80, edgecolors='white', linewidth=1)
plt.plot(observDF['Time'], y_pred_time, color='red', linewidth=3, label=f'Regression Line: y = {model_time.intercept_:.3f} + {model_time.coef_[0]:.3f}x')

# Add coordinate points for each data point
for i, row in observDF.iterrows():
    plt.annotate(f'({row["Time"]}, {row["Anxiety"]})', 
                (row['Time'], row['Anxiety']),
                xytext=(5, 5), textcoords='offset points',
                fontsize=9, alpha=0.8, color='darkgreen',
                bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.7, edgecolor='none'))

# Add some styling
plt.xlabel('Time', fontsize=12, fontweight='bold')
plt.ylabel('Anxiety Level', fontsize=12, fontweight='bold')
plt.title('Relationship Between Time and Anxiety\nWith Linear Regression Line and Coordinate Points', fontsize=14, fontweight='bold')
plt.legend(fontsize=11)
plt.grid(True, alpha=0.3)

# Add R-squared and correlation info
r_squared_time = r2_score(y_time, y_pred_time)
correlation_time = np.corrcoef(observDF['Time'], observDF['Anxiety'])[0,1]
plt.text(0.05, 0.95, f'R² = {r_squared_time:.4f}\nCorrelation = {correlation_time:.4f}', 
         transform=plt.gca().transAxes, fontsize=11, verticalalignment='top',
         bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.8))

plt.tight_layout()
plt.show()

# Comment on the fit
print("\n=== ANALYSIS OF THE TIME-ANXIETY FIT ===")
print(f"The regression line shows a {('strong' if abs(correlation_time) > 0.7 else 'moderate' if abs(correlation_time) > 0.5 else 'weak')} relationship (R² = {r_squared_time:.4f})")
print(f"between Time and Anxiety, with a correlation of {correlation_time:.4f}.")
print(f"\nKey observations:")
print(f"1. The true relationship includes Time with a coefficient of 0.1")
print(f"2. Our estimated coefficient is {model_time.coef_[0]:.4f}")
print(f"3. The model explains {r_squared_time:.1%} of the variance in Anxiety")
print(f"4. This is much weaker than the StressSurvey relationship, but Time is still part of the true model")
```

### Commentary on the Time-Anxiety Relationship

**What This Shows Us**: The relationship between Time and Anxiety is much weaker than what we saw with StressSurvey. This makes sense because Time is only one component of the true relationship, and it has a relatively small coefficient (0.1) in the actual data-generating process.







